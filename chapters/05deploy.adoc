== 集群部署 ==
 
上一章安装和配置Tuatara后,会提示下一步操作的地址以及账号和密码完成后的提示，打开浏览器，导航到 http://tdp-dev2.tdata.com:8080

输入账号 `admin` 以及密码 `admin` 进行登陆。

image::{imagedir}/Tuatara-login.png[alt="登陆"]

登陆成功后，开始创建集群，点击 `创建集群` 视图中的"启动安装向导"按钮。开始使用向导来部署集群。


=== 添加集群服务器 ===

首先，需要给您的集群设置一个集群名字，集群名字不能包含特殊字符，当前仅支持字母以及下划线(_)。这里我们假定集群名为 `tdp_test`。点击“下一步”

image::{imagedir}/clustername.png[alt="cluster name"]


这个页面是选择要安装的堆栈版本，默认为{prodver}。”高级资源库选项“ 里设定获取软件包的仓库地址，这里已经设定完毕，无需修改。点击”下一步“”

image::{imagedir}/choosestack.png[alt="choose stack version"]


这个页面添加集群中的服务器。目标主机使用FQDN名字，每行一个，也可以使用正则表达式。我们这里填写。

............................................................................
tdp-dev1.tdata.com
tdp-dev2.tdata.com
tdp-dev3.tdata.com
............................................................................


SSH私钥指的是当前运行 `Tuatara Server`（这里是 `tdp-dev2.tdata.com` ) 服务器上 `root` 账号的私钥。可以通过登录到该服务器，然后查看 `/root/.ssh/id_rsa` 文件，复制该文件的内容，并粘贴到主机注册信息下面的输入框里。然后点击“注册并确定”按钮。

image::{imagedir}/choosenodes.png[alt="choose cluster nodes"]


接下来，向导将会在每个集群中的服务器安装 `Tuatara Agent` 并进行注册，同时检测每个服务器可能存在的性能缺陷，并给出警告。 检测完毕后，点击”下一步“

image::{imagedir}/nodes-register.png[alt="cluster nodes register"]


=== 安装集群组件 ===

该页面列出了当前{prodshortname} {prodver} 的所有有效组件，默认是全部安装所有组件，您也可以针对您的业务选择需要的组件。这里我们选择

............................................................................
HDFS
YARN + MapReduces
Tez
Hive
HBase
Zookeeper
Spark
Pig
Ambari Metrics
............................................................................

点击”下一步“。

NOTE: 所有的组件在之后还可以添加和删除，所以我们建议总是从选择目前需要的组件开始。


image::{imagedir}/choosecomps.png[alt="choose cluster components"]


向导会依据集群内节点的数量和资源自动分配Master组件到各自服务器，在这里，您可以自行指定每个Master组件分配到哪台服务器上。分配完毕后，点击 “下一步”。

NOTE: 如果组件右侧有 icon:plus[role="green"] 符号，则表示该组件可以分配到多个服务器，比如 `Zookeeper Server` ,`HBase Master`。

image::{imagedir}/masterdeploy.png[alt="choose Master components"]


接下来选择Slave组件的分配情况，这里我们把三台服务器都当成 `Datenode` 节点以及 `YARN NodeManager` 以及 `HBase RegionServer`。

image::{imagedir}/slavedeploy.png[alt="choose Slave components"]


这个页面定义一些服务器的基本参数，重要的参数包括

Namenode:: 定义Namenode数据的保存路径
Datanode:: 定义Datanode的数据保存路径，填写数据磁盘的挂载路径，一行一个。
Hive Metastore:: 配置Hive Metastore所需要的数据库连接参数。

我们推荐使用MySQL来保存 `Hive Metastore` 以及以后需要关系型数据库的服务的信息。假定我们在 `tdp-dev3.tdata.com` 上来安装 `MySQL Server`。SSH 登陆到 `tdp-dev3.tdata.com` ，首先安装必要的软件包。

............................................................................
yum install -y mariadb-server mariadb-libs mariadb
systemctl enable mariadb
systemctl start mariadb
............................................................................

  
NOTE: 如果是CentOS 6.x版本，则执行 `yum install -y mysql-server mysql-libs mysql && service mysql start`

然后创建必要的账号和数据库

[source,sql]
----
MariaDB [(none)]> drop user ''@'localhost'; // <1>
Query OK, 0 rows affected (0.00 sec)

MariaDB [(none)]> drop user ''@'tdp-dev3.tdata.com';  // <1>
Query OK, 0 rows affected (0.00 sec)

MariaDB [(none)]> grant all on hive.* to 'hive'@'%' identified by 'hive123'; // <2>
Query OK, 0 rows affected (0.00 sec)

MariaDB [(none)]> create database hive; // <3>
Query OK, 1 row affected (0.00 sec)
----
<1> 删除用户名为空的账号
<2> 创建Hive Metastore服务连接数据库的账号和密码，这里账号为 `hive` ，密码为 `hive123`
<3> 创建Hive Metastore服务需要的数据库，这里数据库名为 `hive`
	
回到安装向导页面，在 `Hive`标签页的 `Advanced`标签里,依据刚才创建的数据库账号和数据库名称，填写对应的内容

............................................................................
Hive Database: Existing MySQL Database 
Database Host: tdp-dev3.tdata.com
Database Password: hive123
............................................................................

填写完成后，点击 image:{imagedir}/conntest.png[alt="测试连接"] 按钮进行连接测试。 如果连接成功，则会给出 "连接成功" 的提示。

完成上述步骤后，点击 ”下一步”。

image::{imagedir}/srvsetup.png[alt="setup components"]


向导开始检测所有配置的有效性，如果没有问题，则可以点击 “部署” 按钮开始部署。部署的时间根据所有的组件不同，而所用的时间不同，但都应该在1小时内能完成。

image::{imagedir}/srvinstall.png[alt="Installing Components"]


一旦安装成功，点击“下一步”按钮。


image::{imagedir}/srvcomplete.png[alt="Install completed"]


=== 完成安装 ===

显示安装小结，点击“完成”按钮，完成集群安装向导。


image::{imagedir}/wizardfinish.png[alt="Wizard finish"]


向导完成后，将会回到集群管理界面，这里能看到当前集群的状态。

image::{imagedir}/overview.png[alt="Cluster Management Overview"]
 